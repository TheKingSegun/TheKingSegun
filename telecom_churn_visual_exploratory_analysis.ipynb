{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ICLp7CtiV0h"
      },
      "source": [
        "# Visual Exploratory analysis of Telecom churn data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "861BYIJciV0l"
      },
      "source": [
        "## 1. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edzdAnvUiV0l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "YLwoJhZ-iV0m",
        "outputId": "469a4b2d-a0d8-4d05-e88c-c894874ed53c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'telecom_churn.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-75c956d63322>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'telecom_churn.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'telecom_churn.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('telecom_churn.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6uJlP-kiV0n"
      },
      "outputs": [],
      "source": [
        "df.info();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCN9A4dbiV0n"
      },
      "source": [
        "The last column 'churn' is our target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2zC9GyhiV0n"
      },
      "source": [
        "# 2. Univariate visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKQ8xT0uiV0o"
      },
      "source": [
        "Univariate analysis looks at one feature at a time. when we analyse a feature independently, we are usually interested of its values and ignore other features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr0OobLuiV0p"
      },
      "source": [
        "### 2.1 Quantitative features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb9lSR6wiV0p"
      },
      "source": [
        "Quantitative features take on ordered numerical values. These values can be discrete ( i.e integers), or continuous ( i.e real numbers) and usually express a count or measurement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmjj1moniV0p"
      },
      "source": [
        "### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZieGGaB8iV0p"
      },
      "outputs": [],
      "source": [
        "features = ['total day minutes', 'total intl calls']\n",
        "df[features].hist(figsize=(10,4));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-xHPz4miV0q"
      },
      "source": [
        "A histogram groups values into bins of equal value range. The shape of the histogram provides the clues about the underlying distribution type. We can also spot any skewness in tis shape.  Knowing a distribution of the feature values is importtant when we use machine leaning methods that assume a particular type of it, most often Gaussian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaj7zObqiV0q"
      },
      "source": [
        "In the above plot 'total day minutes' is normally distributed, but the 'total intl calls' is skewed right ( itis tail is longer on the right )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4ttLlviiV0r"
      },
      "source": [
        "## Density plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-d6r89OiV0r"
      },
      "source": [
        "Another ways to understand the distribution is by using the density plots or more formally Kernal Density Plots. These are like a smoothed version of histogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_uWw8nSiV0r"
      },
      "outputs": [],
      "source": [
        "df[features].plot(kind='density', subplots=True, layout=(1,2),\n",
        "                  sharex=False, figsize=(10,4));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6SOUH-_iV0r"
      },
      "source": [
        "We can also pot distribution with seaborn's distplot().  distplot() displays the histogram with kernel density estimate on top. Let us see the distribution of 'ttal day minutes'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh0PyqG0iV0s"
      },
      "outputs": [],
      "source": [
        "x = df['total intl calls']\n",
        "sns.distplot(x);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yHUskDfiV0s"
      },
      "source": [
        "The height of the histogram bars here is normed and shows the density rather than the number of examles in each bin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe1txMTCiV0t"
      },
      "source": [
        "### Box plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsCerLTfiV0t"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x = 'total intl calls', data = df);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk4ErsFUiV0t"
      },
      "source": [
        "Let's see how to interpret a box plot. Its components are a box (obviously, this is why it is called a box plot), the so-called whiskers, and a number of individual points (outliers).\n",
        "\n",
        "The box by itself illustrates the interquartile spread of the distribution; its length is determined by the 25th(Q1) and 75th(Q3) percentiles. The vertical line inside the box marks the median (50%) of the distribution.\n",
        "\n",
        "The whiskers are the lines extending from the box. They represent the entire scatter of data points, specifically the points that fall within the interval (Q1−1.5⋅IQR,Q3+1.5⋅IQR), where IQR=Q3−Q1 is the interquartile range.\n",
        "\n",
        "Outliers that fall out of the range bounded by the whiskers are plotted individually as black points along the central axis.\n",
        "\n",
        "We can see that a large number of international calls is quite rare in our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOZ84gVXiV0u"
      },
      "source": [
        "### Violin plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RygTRz0giV0v"
      },
      "source": [
        "violinplot is also another distribution plot.\n",
        "\n",
        "violinplot displays the kernal density estimate on both sides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T70qwXfwiV0v"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1,2, sharey=True, figsize=(6,4))\n",
        "sns.boxplot(data=df['total intl calls'], ax=axes[0]);\n",
        "sns.violinplot(data=df['total intl calls'], ax = axes[1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTUZScAoiV0v"
      },
      "source": [
        "The difference between the box and violin plots is that the former illustrates certain statistics concerning individual examples in a dataset while the violin plot concentrates more on the smoothed distribution as a whole.\n",
        "\n",
        "In our case, the violin plot does not contribute any additional information about the data as everything is clear from the box plot alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyI1-nsoiV0v"
      },
      "source": [
        "### Numerical statisticks of the distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_caa_nrqiV0v"
      },
      "outputs": [],
      "source": [
        "df[features].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOf8zBwriV0w"
      },
      "source": [
        "### 2.2 Categorical and Binary features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOfBRfvUiV0w"
      },
      "source": [
        "Categorical features take on a fixed number of values. Each of these values assigns an observation to a corresponding group, known as a category, which reflects some qualitative property of this example. Binary variables are an important special case of categorical variables when the number of possible values is exactly 2. If the values of a categorical variable are ordered, it is called ordinal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68lu3_beiV0w"
      },
      "source": [
        "### Frequency table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2_xG75WiV0w"
      },
      "source": [
        "Let us check the distribution of our target varible (i.e churn )\n",
        "First we will print frequency table, which shows how freqent each value of the categorical variable is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYOFJYd0iV0x"
      },
      "outputs": [],
      "source": [
        "df['churn'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpZuUdF2iV0x"
      },
      "source": [
        "By default, the entries in the output are sorted from the most to the least frequently-occurring values.\n",
        "\n",
        "In our case, the data is not balanced; that is, our two target classes, loyal and disloyal customers, are not represented equally in the dataset. Only a small part of the clients canceled their subscription to the telecom service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aorHi_6tiV0x"
      },
      "source": [
        "### Bar plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vuhh6LEPiV0y"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,2))\n",
        "\n",
        "sns.countplot(x='churn', data = df, ax = axes[0])\n",
        "sns.countplot(x='customer service calls', data = df, ax = axes[1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMuRQFU4iV0y"
      },
      "source": [
        "We have seen the histograms above, now we have seen the bar plots, they look similar, but there are several differences between them:\n",
        "\n",
        "1. Histograms are best suited for looking at the distribution of numerical variables while bar plots are used for categorical features.\n",
        "2. The values on the X-axis in the histogram are numerical; a bar plot can have any type of values on the X-axis: numbers, strings, booleans\n",
        "3. The histogram's X-axis is a Cartesian coordinate axis along which values cannot be changed; the ordering of the bars is not predefined. Still, it is useful to note that the bars are often sorted by height, that is, the frequency of the values. Also, we we consider ordinal varibles ( like cusotmer service calls in our data), the bars are usually ordered by variable value.\n",
        "\n",
        "The left chart above vividly illustrates the imbalance in our target variable. The bar plot for Customer service calls on the right gives a hint that the majority of customers resolve their problems in maximum 2–3 calls. But, as we want to be able to predict the minority class, we may be more interested in how the fewer dissatisfied customers behave. It may well be that the tail of that bar plot contains most of our churn. These are just hypotheses for now, so let's move on to some more interesting and powerful visual techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29tNoy7QiV0y"
      },
      "source": [
        "# 3. Multivariate visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaLHnyxwiV0-"
      },
      "source": [
        "Multivariate plots allow us to see relationships between two and more different variables, all in one figure. Just as in the case of univariate plots, the specific type of visualization will depend on the types of the variables being analyzed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNFPzDiQiV0_"
      },
      "source": [
        "## 3.1 Quantitative-Quantitative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t048lrYbiV0_"
      },
      "source": [
        "### Correlation matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvEGle7yiV0_"
      },
      "source": [
        "We will analyse the correlations among the numerical variables in our dataset.\n",
        "Let us drop the non-numerical variables and print the correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x95_tsHniV1A"
      },
      "outputs": [],
      "source": [
        "numerical = list(set(df.columns)-set(['state', 'international plan', 'voice mail plan',\n",
        "                                     'area code', 'churn', 'customer service calls']))\n",
        "corr_matrix = df[numerical].corr()\n",
        "corr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqWDQTBFiV1A"
      },
      "source": [
        "let us plot the heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk1iYzvEiV1B"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(corr_matrix);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U06wXinTiV1B"
      },
      "source": [
        "As seen in the correlation plot above, we can notice that there are 4 variables ( 'total day charge', 'total eve charge', 'total night charge', 'total intl charge' ) are directly depended on ('total day call', 'total eve calls', 'total night calls', 'total intl calls').\n",
        "These are called dependent variables and can be leftout since they do not contribute any additional information. so let's drop them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glg9U2m9iV1C",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "numerical = list(set(numerical)-set(['total day charge', 'total eve charge', 'total night charge', 'total intl charge']))\n",
        "corr_matrix = df[numerical].corr()\n",
        "sns.heatmap(corr_matrix);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r0JCtqSiV1C"
      },
      "source": [
        "### Scatter plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fL-Z99RiV1D"
      },
      "source": [
        "The scatter plot displays values of two numerical variables as Cartesian coordinates in 2D. Scatter plots in 3D are also possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wHscngviV1D"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df['total day minutes'], df['total night minutes']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA5LPQgQiV1F"
      },
      "source": [
        "The above plot is not interesting, these features are non-correlated, because the ellipse like shape is aligned with the axes.\n",
        "\n",
        "Let us use the seaborn's jointplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxpbj9yviV1F"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='total day minutes', y='total night minutes', data=df, kind = 'scatter');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4d_NCw0iV1L"
      },
      "source": [
        "The jointplot plots two histograms that may be useful in some cases.\n",
        "Using the jointplot, we can also get a smoothed version of our bivariate distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-T90OzBiV1L"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='total day minutes', y='total night minutes', data = df, kind = 'kde', color='g');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ydUUB2OiV1M"
      },
      "source": [
        "this is nothing but a bivariate version of Kernal Density Plot discussed earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgm7-p_EiV1M"
      },
      "source": [
        "### Scatterplot matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWyurHeXiV1N"
      },
      "outputs": [],
      "source": [
        "# pairplot() may become very slow with the SVG format\n",
        "%config InlineBackend.figure_format = 'png'\n",
        "sns.pairplot(df[numerical]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoI3I35uiV1N"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHXuGXLRiV1O"
      },
      "source": [
        "### 3.2 Quantitative - Categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZamEKk3iV1O"
      },
      "source": [
        "we will try to gain new insights for churn prediction from the interactions between the numerical and categorical features.\n",
        "\n",
        "we will try to interpret how the input variables are related to the target varible 'churn'\n",
        "\n",
        "Previously, you learned about scatter plots. Additionally, their points can be color or size coded so that the values of a third categorical variable are also presented in the same figure. We can achieve this with the scatter() function seen above, but, let's try a new function called lmplot() and use the parameter hue to indicate our categorical feature of interest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtCUwDY6iV1P"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='total day minutes', y='total night minutes', data = df, hue='churn', fit_reg=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McoDioE1iV1P"
      },
      "source": [
        "It seems that our small proportion of disloyal customers lean towards the top-right corner; that is, such customers tend to spend more time on the phone during both day and night. But this is not absolutely clear, and we won't make any definitive conclusions from this chart.\n",
        "\n",
        "Now, let’s create box plots to visualize the distribution statistics of the numerical variables in two disjoint groups: the loyal customers (churn=False) and those who left (churn=True)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyUf1BfTiV1P"
      },
      "outputs": [],
      "source": [
        "numerical = list(set(numerical)-set(['phone number']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaGfT19IiV1Q"
      },
      "outputs": [],
      "source": [
        "# sometimes we can analyse an ordinal variables just as numerical one\n",
        "numerical.append('customer service calls')\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(10,7))\n",
        "for idx, feat in enumerate(numerical):\n",
        "    ax = axes[int(idx / 4), idx % 4]\n",
        "    sns.boxplot(x='churn', y = feat, data=df, ax=ax)\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel(feat)\n",
        "fig.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Dz97NKiV1Q"
      },
      "source": [
        "From the above charts, we can notice that there is a lot of discrepancy in distribution between the two groups is for three variables, 'total day minutes', 'cusotmer service calls' and 'number vmail messages'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNGxoq5HiV1R"
      },
      "source": [
        "Let's look at the distribution of day minutes spoken for the loyal and disloyal cusotmers separately. We will create box and violin plots for 'total day minutes' grouped by the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4k1Ajz3iV1S",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1, 2, sharey=True, figsize=(10, 4))\n",
        "\n",
        "sns.boxplot(x='churn', y='total day minutes', data = df, ax = axes[0]);\n",
        "sns.violinplot(x='churn', y='total day minutes', data = df, ax = axes[1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6fDPg_MiV1S"
      },
      "source": [
        "In this case, the violin plot does not contribute any additional information about our data as everything is clear from the box plot alone: disloyal customers tend to talk on the phone more.\n",
        "\n",
        "An interesting observation: on average, customers that discontinue their contracts are more active users of communication services. Perhaps they are unhappy with the tariffs, so a possible measure to prevent churn could be a reduction in call rates. The company will need to undertake additional economic analysis to find out whether such measures would be beneficial.\n",
        "\n",
        "When we want to analyze a quantitative variable in two categorical dimensions at once, there is a suitable function for this in the seaborn library called catplot(). For example, let's visualize the interaction between total day minutes and two categorical variables in the same plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLc2PNGNiV1T"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x='churn', y = 'total day minutes', col='customer service calls',\n",
        "           data=df[df['customer service calls'] < 8], kind = 'box', col_wrap=4, height=3, aspect=0.8);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXN0GDuhiV1U"
      },
      "source": [
        "From the above plots, we can notice that, starting with 4 calls, total day minutes may no longer be the main factor for customer churn. Perhaps, in addition to ur previous guess about the tariffs, there are cusomters that are dissatisfied with the service due to other problems, which might lead to fewer number of day minutes spent on calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z18-2IbFiV1U"
      },
      "source": [
        "### 3.3 Categorical-Categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agJY0rqJiV1V"
      },
      "source": [
        "As we saw earlier in this article, the variable Customer service calls has few unique values and, thus, can be considered either numerical or ordinal. We have already seen its distribution with a count plot. Now, we are interested in the relationship between this ordinal feature and the target variable Churn.\n",
        "\n",
        "Let's look at the distribution of the number of calls to the customer service, again using a count plot. This time, let's also pass the parameter hue=Churn that adds a categorical dimension to the plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzK6RoSDiV1V"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='customer service calls', hue='churn', data=df);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbEi4amsiV1W"
      },
      "source": [
        "An observation: the churn rate increases significantly after 4 or more calls to the customer service.\n",
        "\n",
        "Now, let's look at the relationship between Churn and the binary features, International plan and Voice mail plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3Y3aGOuiV1W"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1, 2, sharey = True, figsize=(10,4))\n",
        "\n",
        "sns.countplot(x = 'international plan', hue = 'churn', data = df, ax = axes[0]);\n",
        "sns.countplot(x = 'voice mail plan', hue = 'churn', data = df, ax = axes[1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCfKTeKLiV1X"
      },
      "source": [
        "An observation: when International Plan is enabled, the churn rate is much higher; the usage of the international plan by the customer is a strong feature. We do not observe the same effect with Voice mail plan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muNJjH9piV1X"
      },
      "source": [
        "### Contingency table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX5yxLLHiV1Y"
      },
      "source": [
        "In addition to using graphical means for categorical analysis, there is a traditional tool from statistics: a contingency table, also called a cross tabulation. It represents multivariate frequency distribution of categorical variables in tabular form. In particular, it allows us to see the distribution of one variable conditional on the other by looking along a column or row.\n",
        "\n",
        "Let's try to see how Churn is related to the categorical variable State by creating a cross tabulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgwj0HSXiV1Y"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(df['state'], df['churn'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeldqyWwiV1Z"
      },
      "source": [
        "In the case of State, the number of distinct values is rather high: 51. We see that there are only a few data points available for each individual state – only 3 to 17 customers in each state abandoned the operator. Let's ignore that for a second and calculate the churn rate for each state, sorting it from high to low:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ0-V8pEiV1Z"
      },
      "outputs": [],
      "source": [
        "df.groupby(['state'])['churn'].agg([np.mean]).sort_values(by='mean', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fgz9VFeiV1a"
      },
      "source": [
        "It seems that the churn rate in New Jersey and California are above 25% and less than 6% for Hawaii and Alaska. However, these conclusions are based on too few examples, and our observation could be a mere property of our particular dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRYH3e67iV1a"
      },
      "source": [
        "## 4. Whole dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBuaSykAiV1b"
      },
      "source": [
        "### 4.1 Naive approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtc4fgM0iV1b"
      },
      "source": [
        "we have seen the different faces of this dataset by guessing features and selecting a small number of them at a time for visualizaton.\n",
        "\n",
        "We could use hist() or create a scatterplot matrix with pairplot() for the whole dataset to look at all of our features simultaneously. But, when the number of features is high enough, this kind of visual analysis quickly becomes slow and inefficient. Besides, we would still be analyzing our variables in a pairwise fashion, not all at once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1F2aN_MiV1c"
      },
      "source": [
        "### 4.2  Dimensionality reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imHP_vioiV1c"
      },
      "source": [
        "Most real-world datasets have many features, sometimes, many thousands of them. Each of them can be considered as a dimension in the space of data points. Consequently, more often than not, we deal with high-dimensional datasets, where entire visualization is quite hard.\n",
        "\n",
        "To look at a dataset as a whole, we need to decrease the number of dimensions used in visualization without losing much information about data. This task is called dimensionality reduction and is an example of an unsupervised learning problem because we need to derive new, low-dimensional features from the data itself, without any supervised input.\n",
        "\n",
        "One of the well-known dimensionality reduction methods is Principal Component Analysis (PCA). Its limitation is that it is a linear algorithm that implies certain restrictions on the data.\n",
        "\n",
        "There are also many non-linear methods, collectively called Manifold Learning. One of the best-known of them is t-SNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zlNZ5w7iV1d"
      },
      "source": [
        "### 4.3 t-SNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqxYbAVxiV1d"
      },
      "source": [
        "The name of the method looks complex and a bit intimidating: t-distributed Stohastic Neighbor Embedding.\n",
        "\n",
        "Its basic idea is simple: find a projection for a high-dimensional feature space onto a plane (or a 3D hyperplane, but it is almost always 2D) such that those points that were far apart in the initial n-dimensional space will end up far apart on the plane. Those that were originally close would remain close to each other.\n",
        "\n",
        "Essentially, neighbor embedding is a search for a new and less-dimensional data representation that preserves neighborship of examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXVvGn3SiV1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0gdf0oiV1e"
      },
      "source": [
        "we will leave out the state and churn features and convert the values Yes/No of the binary features into numerical values using pandas.Series.map():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0erQXUBiV1e"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['churn', 'state', 'phone number'], axis = 1)\n",
        "X['international plan'] = X['international plan'].map({'yes':1, 'no':0})\n",
        "X['voice mail plan'] = X['voice mail plan'].map({'yes':1,'no':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDIABc88iV1f"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Nut3PZiV1f"
      },
      "source": [
        "We also need to normalize the data. For this, we will subtract the mean from each variable and divide it by its standard deviation. All of this can be done with StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7tBD-9PiV1g"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtGS0S7KiV1g"
      },
      "source": [
        "Let us build t-SNE representation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRNp9vPIiV1h"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "tsne = TSNE(random_state=17)\n",
        "tsne_repr = tsne.fit_transform(X_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7oXQ2JSiV1h"
      },
      "outputs": [],
      "source": [
        "plt.scatter(tsne_repr[:,0], tsne_repr[:,1], alpha=0.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XNBS0RTiV1i"
      },
      "source": [
        "Let’s color this t-SNE representation according to the churn (blue for loyal customers, and orange for those who churned)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmFEG9wKiV1i"
      },
      "outputs": [],
      "source": [
        "plt.scatter(tsne_repr[:,0], tsne_repr[:,1], c=df['churn'].map({False:'blue', True:'orange'}), alpha=0.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vvA0ZE4iV1j"
      },
      "source": [
        "We can see that customers who churned are concentrated in a few areas of the lower dimensional feature space.\n",
        "\n",
        "To better understand the picture, we can also color it with the remaining binary features: International Plan and Voicemail. Orange dots here indicate instances that are positive for the corresponding binary feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGPtLdDTiV1j"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1, 2, sharey=True, figsize=(12,5))\n",
        "\n",
        "for i, name in enumerate(['international plan', 'voice mail plan']):\n",
        "    axes[i].scatter(tsne_repr[:,0], tsne_repr[:,1],\n",
        "                c=df[name].map({'yes' : 'orange', 'no':'blue'}), alpha=0.5);\n",
        "    axes[i].set_title(name);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLY0KX55iV1j"
      },
      "source": [
        "From the above plots, many dissatisfied customers who canceled their subscription are crowded together in one cluster representing the people with the international plan but no voice mail."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}